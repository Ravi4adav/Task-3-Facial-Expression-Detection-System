# **Task-3:** Facial Expression Detection model

**COMPANY:** CODTECH IT SOLUTIONS

**NAME:** RAVI YADAV

**INTERN ID:** CT08IIJ

**DOMAIN:** MACHINE LEARNING

**DURATION:** 4 WEEKS

**MENTOR:** NEELA SANTOSH


# **Description**

## Project Overview
The **Facial Expression Recognition System** is a deep learning-based model that classifies human emotions from facial images. This system is built using **CNN (Convolutional Neural Networks)** and achieves **75% validation accuracy** in classifying six different facial expressions. The goal of this project is to enable real-time emotion detection for applications such as sentiment analysis, human-computer interaction, and mental health monitoring.

## Features
- **Emotion Classification:** The model predicts six facial expressions:
  - üò† Angry
  - ü§¢ Disgust
  - üò® Fear
  - üòÄ Happy
  - üòê Neutral
  - üò¢ Sad
- **Deep Learning-Based:** Uses only **CNN layers** for feature extraction and classification.
- **High Accuracy:** Achieves **75% validation accuracy** on the dataset.
- **TensorFlow & Keras Implementation:** Built entirely using TensorFlow and Keras frameworks.

## Dataset
The model is trained on a well-structured facial expression dataset containing labeled images for each emotion category. The dataset consists of:
- Preprocessed grayscale facial images.
- Balanced data distribution among six classes.

## Technologies Used
- **Programming Language:** Python
- **Deep Learning Framework:** TensorFlow, Keras
- **Data Processing:** NumPy, OpenCV
- **Visualization:** Matplotlib, Seaborn

## Model Architecture
The **CNN-based model** is designed to extract key facial features and classify expressions. The architecture includes:
1. **Convolutional Layers:** Extract spatial features from facial images.
2. **Pooling Layers:** Reduce feature map dimensions while preserving important information.
3. **Fully Connected Layers:** Flattened feature maps are fed into dense layers for final classification.
4. **Activation Functions:** ReLU for hidden layers and Softmax for the output layer.

## Training & Evaluation
- **Loss Function:** Categorical Crossentropy
- **Optimizer:** Adam
- **Metrics:** Accuracy, Precision, Recall
- **Training Method:** The model is trained using **batch gradient descent** with proper regularization techniques to prevent overfitting.
- **Evaluation:** Achieved **75% validation accuracy** after fine-tuning hyperparameters.

## Future Enhancements
- **Real-Time Detection:** Implementing real-time facial expression analysis using OpenCV.
- **Additional Emotions:** Expanding the classification categories.
- **Transfer Learning:** Using pre-trained models like VGG, ResNet for improved accuracy.
- **Larger Dataset:** Training on a more diverse dataset to enhance generalization.

## Conclusion
The **Facial Expression Recognition System** is a robust deep-learning model capable of classifying six human emotions with **75% validation accuracy**. Built with **CNN layers** using TensorFlow and Keras, this system has potential applications in sentiment analysis, interactive AI systems, and healthcare. Future improvements will focus on enhancing accuracy and real-time processing capabilities.

